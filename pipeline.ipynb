{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "import pickle \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.20.3\n",
      "    Uninstalling scikit-learn-0.20.3:\n",
      "      Successfully uninstalled scikit-learn-0.20.3\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "azureml-train-automl-runtime 1.11.0.post1 requires numpy<1.17.0,>=1.16.0, but you'll have numpy 1.18.1 which is incompatible.\n",
      "azureml-train-automl-runtime 1.11.0.post1 requires scikit-learn<=0.20.3,>=0.19.0, but you'll have scikit-learn 0.23.2 which is incompatible.\n",
      "azureml-automl-runtime 1.11.0 requires numpy<1.17.0,>=1.16.0, but you'll have numpy 1.18.1 which is incompatible.\n",
      "azureml-automl-runtime 1.11.0 requires scikit-learn<=0.20.3,>=0.19.0, but you'll have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
      "Successfully installed scikit-learn-0.23.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
    "except ImportError:\n",
    "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "\n",
    "import pandas as pd\n",
    "insurance_df = pd.read_csv(\"/Users/maryam/Documents/Cineplex/Insurance prediction/nsurance.csv\")\n",
    "insurance_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = insurance_df.drop(['charges'], axis=1) # drop labels for training set\n",
    "\n",
    "insurance_labels = insurance_df['charges'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(insurance, insurance_labels, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num= X_train.drop([ 'sex','smoker','region'],axis=1)\n",
    "X_train_cat = X_train[['sex', 'smoker','region']]\n",
    "num_attribs = list(X_train_num)\n",
    "cat_attribs = ['sex', 'region','smoker']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'region', 'smoker']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'bmi', 'children']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self.feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "#         return X[ self.feature_names ].values\n",
    "          df = X.copy()\n",
    "        # convert columns to categorical\n",
    "          for name in df.columns.to_list():\n",
    "                col = pd.Categorical(df[name])\n",
    "                df[name] = col.codes\n",
    "    \n",
    "    #returns numpy array\n",
    "          return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', cat_pipeline, cat_attribs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST WITH GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "        'n_estimators': randint(low=4, high=30),\n",
    "        'max_features': randint(low=1, high=2),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=5, cv=5, scoring='neg_mean_squared_error', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcb144e9950>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fcb144e9910>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "rnd_search.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred= rnd_search.predict(X_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078.2760275596966"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mse = mean_squared_error(y_train, y_train_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = insurance.iloc[:5]\n",
    "some_labels = insurance_labels.iloc[:5]\n",
    "some_data_prepared= full_pipeline.transform(some_data)\n",
    "y_rf_pred= rnd_search.predict(some_data_prepared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23079.20681739,  2098.56916087,  6633.14744783, 17570.04395522,\n",
       "        8239.90013913])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate on test set\n",
    "\n",
    "x_test_prepared = full_pipeline.transform(X_test)\n",
    "y_test_pred= rnd_search.predict(x_test_prepared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mse = mean_squared_error(y_test, y_test_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "math.trunc(rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6025.626299576042"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR REGRESSIOR\n",
    "lr= LinearRegression()\n",
    "X_train_prepared_lr = full_pipeline.fit_transform(X_train)\n",
    "lr.fit(X_train_prepared_lr, y_train)\n",
    "y_train_pred_lr= lr.predict(X_train_prepared_lr)\n",
    "lin_mse = mean_squared_error(y_train, y_train_pred_lr)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089.478791099683"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate on test set\n",
    "\n",
    "x_test_prepared_lr = full_pipeline.transform(X_test)\n",
    "y_test_pred_lr= lr.predict(x_test_prepared_lr)\n",
    "lr_mse = mean_squared_error(y_test, y_test_pred_lr)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3567.7913053780503"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN WITH GRADIENT BOOSTING\n",
    "gb = GradientBoostingRegressor(random_state=0)\n",
    "X_train_prepared_gb = full_pipeline.fit_transform(X_train)\n",
    "gb.fit(X_train_prepared_gb, y_train)\n",
    "y_train_pred_gb= gb.predict(X_train_prepared_gb)\n",
    "gb_mse = mean_squared_error(y_train, y_train_pred_gb)\n",
    "gb_rmse = np.sqrt(gb_mse)\n",
    "gb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4733.387466083859"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate on test set\n",
    "\n",
    "x_test_prepared_gb = full_pipeline.transform(X_test)\n",
    "y_test_pred_gb= gb.predict(x_test_prepared_gb)\n",
    "gb_mse = mean_squared_error(y_test, y_test_pred_gb)\n",
    "gb_rmse = np.sqrt(gb_mse)\n",
    "gb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13163.20160625537"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN WITH SVR\n",
    "svr = SVR(epsilon=0.2)\n",
    "X_train_prepared_svr = full_pipeline.fit_transform(X_train)\n",
    "svr.fit(X_train_prepared_svr, y_train)\n",
    "y_train_pred_svr= svr.predict(X_train_prepared_svr)\n",
    "svr_mse = mean_squared_error(y_train, y_train_pred_svr)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11701.474462654018"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate on test set\n",
    "\n",
    "x_test_prepared_svr = full_pipeline.transform(X_test)\n",
    "y_test_pred_svr= svr.predict(x_test_prepared_svr)\n",
    "svr_mse = mean_squared_error(y_test, y_test_pred_svr)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATA PREPRATION PIPLINE AND FINAL MODEL\n",
    "\n",
    "# model gb\n",
    "gb_model = gb\n",
    "Pkl_Filename = \"gb.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(gb_model, file)\n",
    "#...\n",
    "\n",
    "\n",
    "# model lr\n",
    "lr_model = lr\n",
    "Pkl_Filename = \"lrm.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(lr_model, file)\n",
    "#...\n",
    "\n",
    "\n",
    "\n",
    "# model rf\n",
    "rf_model = rnd_search\n",
    "Pkl_Filename = \"rf.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(rf_model, file)\n",
    "#...\n",
    "\n",
    "\n",
    "# model svr\n",
    "svr_model = svr\n",
    "Pkl_Filename = \"svr.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(svr_model, file)\n",
    "#...\n",
    "\n",
    "\n",
    "# pipline\n",
    "data_prepration = full_pipeline\n",
    "Pkl_Filename = \"data_prepration.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(data_prepration, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['sex', 'region', 'smoker'])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "Pkl_Filename = \"data_prepration.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_data_prepration = pickle.load(file)\n",
    "\n",
    "Pickled_data_prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "Pkl_Filename = \"gb.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_gb_model = pickle.load(file)\n",
    "\n",
    "Pickled_gb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20509.7723566 ,  2881.17205125,  5962.66493576, 11457.89020139,\n",
       "        3552.77660032])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = insurance.iloc[:5]\n",
    "some_labels = insurance_labels.iloc[:5]\n",
    "some_data_prepared= Pickled_data_prepration.transform(some_data)\n",
    "y_rf_pred= Pickled_gb_model.predict(some_data_prepared)\n",
    "y_rf_pred\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "Pkl_Filename = \"lrm.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_lr_model = pickle.load(file)\n",
    "\n",
    "Pickled_lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25168.12332877,  2960.4392921 ,  6001.69173246,  3956.36922799,\n",
       "        5765.07061452])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = insurance.iloc[:5]\n",
    "some_labels = insurance_labels.iloc[:5]\n",
    "some_data_prepared= Pickled_data_prepration.transform(some_data)\n",
    "y_rf_pred= Pickled_lr_model.predict(some_data_prepared)\n",
    "y_rf_pred\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.23.2.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
